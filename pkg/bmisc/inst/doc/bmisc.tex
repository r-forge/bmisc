\documentclass[a4paper]{book}
\usepackage[times,hyper]{Rd}
\usepackage{makeidx}
\usepackage[utf8,latin1]{inputenc}
\makeindex{}
\usepackage{Sweave}
\begin{document}
\chapter*{}
\begin{center}
{\textbf{\huge Package `bmisc'}}
\par\bigskip{\large \today}
\end{center}
\begin{description}
\raggedright{}
\item[Type]\AsIs{Package}
\item[Title]\AsIs{Miscellaneous functions}
\item[Version]\AsIs{0.2-12}
\item[Author]\AsIs{Benoit Bruneau}
\item[Maintainer]\AsIs{Benoit Bruneau }\email{benoit.bruneau1@gmail.com}\AsIs{}
\item[Description]\AsIs{This package has different functions that I have accumulated with time. This is the Alpha version.}
\item[Depends]\AsIs{car, lattice, zoo, robustbase, methods}
\item[License]\AsIs{LGPL >= 3.0}
\end{description}
\Rdcontents{\R{} topics documented:}
\newpage
\newpage
\inputencoding{utf8}
\HeaderA{att.strp}{Attibute stripper}{att.strp}
%
\begin{Description}\relax
Strips an object of its attributes
\end{Description}
%
\begin{Usage}
\begin{verbatim}
att.strp(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] the name of an object (\code{vector, matrix, data.frame, array or list})
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function strips an object of its attributes. In the case of a \code{vector}, all attributes are removed. 
For a \code{matrix} or an \code{array}, only \code{c('dim','dimnames')} are kept. When \code{att.strp} is used on a \code{data.frame}, 
all attributes of the variables are striped and only \code{c('names','row.names','na.action', 'class')} are kept for the
\code{data.frame} object.  


\end{Details}
%
\begin{Value}
returns an object of the same \code{class} as the original one.
\end{Value}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}

######################################
#   Creating different objects       #
#    with added attributes (label)   #
######################################

### numerical vector ###
x <- 1:10
attr(x,"label") <- "test1"
attributes(x)

### data frame ###
z=data.frame(x,x)
attr(z,"labels") <- "test2"
attributes(z)
attributes(z[,1])
attributes(z[,2])

### array ###
y=array(x,c(2,2,2))
attr(y,"labels") <- "test3"
attributes(y)
attributes(y[,,1])
attributes(y[,,2])

### list containing the vector, ###
### data frame and array        ###
u=list(x,z,y)
attr(u,"labels") <- "test4"
attributes(u)
attributes(u[[1]])
attributes(u[[2]])
attributes(u[[3]])

######################################
#        attribute stripping         #
######################################
x2=att.strp(x)
z2=att.strp(z)
y2=att.strp(y)
u2=att.strp(u)

######################################
#   verification of the attributes   #
#    for all stripped objects        #
######################################

### numerical vector ###
attributes(x2)

### data frame ###
attributes(z2)
attributes(z2[,1])
attributes(z2[,2])

### array ###
attributes(y2)
attributes(y2[,,1])
attributes(y2[,,2])

### list containing the vector, ###
### data frame and array        ###
attributes(u2)
attributes(u2[[1]])       # vector in the list

attributes(u2[[2]])       # data frame in the list
attributes(u2[[2]][,1])   # data frame in the list
attributes(u2[[2]][,2])   # data frame in the list

attributes(u2[[3]]        # array in the list
attributes(u2[[3]][,,1])  # array in the list
attributes(u2[[3]][,,2])  # array in the list



\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{bmisc}{Miscellaneous functions}{bmisc}
%
\begin{Description}\relax
This package has different functions that I have accumulated with time. I am not the author of all of them even though I have modified most of them. This is the Alpha version.
\end{Description}
%
\begin{Format}

\Tabular{ll}{
Package: & bmisc\\{}
Type: & Package\\{}
Version: & 0.2-12\\{}
Date: & 04-08-2011\\{}
License: & LGPL >= 3.0\\{}

}      
\end{Format}
%
\begin{Details}\relax
For pdf version of the help, write \code{vignette("bmisc")}.
\end{Details}
%
\begin{Author}\relax
Benoit Bruneau

Maintainer: Benoit Bruneau <benoit.bruneau1@gmail.com>

\end{Author}
\newpage
\inputencoding{utf8}
\HeaderA{ceiling.lg}{ceiling largest}{ceiling.lg}
%
\begin{Description}\relax
Ceiling to largest digit
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ceiling.lg(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x }] Numeric vector

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Gives the  ceiling to largest digit (i.e., 54 -> 60).
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
ceiling.lg(250)
ceiling.lg(25000000)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{clean}{Clean a Data Frame}{clean}
%
\begin{Description}\relax
Cleans a \code{data.frame} from a starting point with a defined threshold
\end{Description}
%
\begin{Usage}
\begin{verbatim}
clean(data= x,  col.start =1,  min.val=NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] then name of the \code{data.frame}
\item[\code{col.start}] indicate the columns from which to start reading 
\item[\code{min.val}] \code{numeric}. Read details
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\code{min.val} is the minimum value accepted in a column. Colomns with this value or higher will be kept in the \code{data.frame}.

More will be added to this function.
\end{Details}
%
\begin{Value}
returns the data.frame with the clean columns
\end{Value}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
x=rnorm(50 , 20,  12)
y=runif(50 )
z=rpois(50,  3)
v=x*y/z
t=z*v
pp=data.frame(aa=x,  bb=y, cc=v,  dd=z,  ee=t)
summary(pp)

pp1 = clean(pp, min.val=0.06)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{corr.perm}{Pearson Correlation by Permutation}{corr.perm}
%
\begin{Description}\relax
Tests the Pearson correlation estimate (r) by use of permutation
\end{Description}
%
\begin{Usage}
\begin{verbatim}
corr.perm(x,y,nperm=999)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x,y}] Two vectors of same length used for correlation analysis
\item[\code{nperm}] Number of permutations (default = 999)
\end{ldescription}
\end{Arguments}
%
\begin{Value}
\begin{ldescription}
\item[\code{Correlation }] Pearson r
\item[\code{t.stat }] Calculated test statistic (t)
\item[\code{No.perm }] number of permutations
\item[\code{P.perm }] pvalue estimated by permutations
\item[\code{P.para }] parametric pvalue estimated
\item[\code{inf }] inferior limit of the confidence interval
\item[\code{sup }] superior limit of the confidence interval
\item[\code{df }] degree of freedom
\end{ldescription}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
x <- rnorm(50,0,1)
y <- runif(50,0,1)*x
toto = corr.perm(x, y)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{cv}{Coefficient of Variation (CV)}{cv}
%
\begin{Usage}
\begin{verbatim}
cv(x, na.rm=T)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] an \R{} object (vector, matrix,...)

\item[\code{na.rm}] a logical value indicating whether NA values should be stripped before the computation proceeds

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The coefficient of variation (CV) is the ratio of the standard deviation to the mean.
The CV is defined for the absolute value of the mean to ensure it is always positive. 
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
x=rnorm(50)
cv(x)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{day}{day}{day}
%
\begin{Description}\relax
Day of year as decimal number (001-366).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
day(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{Errbar}{error bars}{Errbar}
%
\begin{Description}\relax
Adds error bars on a plot
\end{Description}
%
\begin{Usage}
\begin{verbatim}
Errbar(x, y, xinf=NULL, xsup=NULL, yinf=NULL, ysup=NULL, yCI=NULL,
       xCI=NULL, cap=0.05,...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x }] numeric vector

\item[\code{y}] numeric vector

\item[\code{xinf, xsup}] numeric vectors containing the upper (xsup) and/or lower (xinf)
limits of the confidence interval for x-axis values.

\item[\code{yinf, ysup}] numeric vectors containing the upper (ysup) and/or lower (yinf)
limit of the confidence interval for y-axis values.

\item[\code{xCI}] numeric vectors containing the confidence intervals for x-axis values.

\item[\code{yCI}] numeric vectors containing the confidence intervals for y-axis values.

\item[\code{...}] additional graphical arguments (\code{\LinkA{par}{par}}) such as \code{col, lty, lwd}
and/or arguments for \code{\LinkA{arrows}{arrows}} .

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
If \code{xCI} and/or \code{yCI} are defined, individually defined limits (ie. \code{xinf, xsup, yinf, ysup}) are not used.
\end{Details}
%
\begin{SeeAlso}\relax
\code{\LinkA{arrows}{arrows}}, \code{\LinkA{par}{par}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- 1:10
y <- x + rnorm(10)

yci <- runif(10)
xci <- runif(10)

plot(x,y, ylim=c(min(y-yci),max(y+yci)))
Errbar( x, y, yCI=yci)

plot(x,y, xlim=c(min(x-xci),max(x+xci)))
Errbar( x, y, xCI=xci )

plot(x,y, ylim=c(min(y-yci),max(y+yci)), xlim=c(min(x-xci),max(x+xci)))
Errbar( x, y, yCI=yci, xCI=xci )

# Gives an Error message
#plot(x,y, ylim=c(min(y-yci),max(y+yci)))  ## adds the yCI and gives
#Errbar( x, y, ysup=1, yCI=yci)            ## an error message for the ysup

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{fct}{Print bmisc functions}{fct}
%
\begin{Description}\relax
Print all functions of bmisc package
\end{Description}
%
\begin{Usage}
\begin{verbatim}
fct()
\end{verbatim}
\end{Usage}
\newpage
\inputencoding{utf8}
\HeaderA{format.hms}{Format seconds into hours}{format.hms}
%
\begin{Description}\relax
Transforms time format
\end{Description}
%
\begin{Usage}
\begin{verbatim}
format.hms(sec)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{sec}] time expressed in seconds

\end{ldescription}
\end{Arguments}
%
\begin{Value}
returns hrs:min:sec
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
format.hms(20000)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{gam.Check}{Some diagnostics for a fitted gam model}{gam.Check}
%
\begin{Description}\relax
Takes a fitted gam object produced by gam() and produces some diagnostic
information about the fitting procedure and results. The default is to produce
4 residual plots, and some information about the convergence of the smoothness
selection optimization.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
gam.Check(b,...)
## Default S3 method:
gam.Check(b,
          main=c("Normal Q-Q Plot","Resids vs. Linear Pred.",
          "Histogram of Residuals","Response vs. Fitted Values"),

          xlab=c("Theorical Quantiles", "Linear Predictor",
          "Residuals","Fitted Values"),

          ylab= c("Sample Quantiles","Residuals","Frequency",
          "Response"),
          
          text=NULL, args.histplot=NULL, ...))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{b}] a fitted gam object as produced by \code{gam()}.
\item[\code{main}] a character vector containing the four titles to be used.
\item[\code{xlab}] a character vector containing the four x labels to be used.
\item[\code{ylab}] a character vector containing the four y labels to be used.
\item[\code{text}] a character or \code{\LinkA{expression}{expression}} vector specifying the text to be written.
\item[\code{args.histplot}] \code{\LinkA{list}{list}} of additional arguments to pass to \code{\LinkA{histplot}{histplot}()}
\item[\code{...}] additional text and graphical parameters (see \code{\LinkA{par}{par}}, \code{\LinkA{mtext}{mtext}})
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function plots 4 standard diagnostic plots, and some other convergence
diagnostics. Usually the 4 plots are various residual plots. The printed
information relates to the optimization used to select smoothing parameters.
For the default optimization methods the information is summarized in a readable
way, but for other optimization methods, whatever is returned by way of convergence
diagnostics is simply printed.

This is a modified version of \code{\LinkA{gam.check}{gam.check}} from \code{mgcv-package} so that
main titles, x labels and y labels can be customized.
\end{Details}
%
\begin{References}\relax
Wood S.N. (2006) Generalized Additive Models: An Introduction with R. Chapman and Hall/CRC Press.
\end{References}
%
\begin{Examples}
\begin{ExampleCode}
library(mgcv)
set.seed(0)
dat <- gamSim(1,n=200)
b<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
plot(b,pages=1)


gam.check(b)                                              

gam.check(b, main=c("A","B","C","D"))                               



\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{get.partial.etas}{get partial etas}{get.partial.etas}
%
\begin{Usage}
\begin{verbatim}
get.partial.etas(model)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{histplot}{histplot}{histplot}
%
\begin{Usage}
\begin{verbatim}
histplot(dat, breaks="Sturges", barc="steelblue", borc="white",
         fit.norm=TRUE, lcol="brown", stat=NULL, 
         stat.lab=c("Mean","Median"), box=TRUE, rug=TRUE, 
         main,...)


\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dat}] one of:
\begin{itemize}

\item a numeric vector
\item an object of class \code{c('norm','lm','aov','glm','gam')} resulting from a
calls to \code{c(\LinkA{norm.test}{norm.test},\LinkA{lm}{lm},\LinkA{aov}{aov},\LinkA{glm}{glm},\LinkA{gam}{gam})}

\end{itemize}


\item[\code{breaks}] one of:
\begin{itemize}

\item a vector giving the breakpoints between histogram cells,
\item a single number giving the number of cells for the histogram,
\item a character string naming an algorithm to compute the
number of cells (see `Details'),
\item a function to compute the number of cells.

\end{itemize}

In the last three cases the number is a suggestion only.

\item[\code{barc}] a color to be used to fill the bars.
\item[\code{borc}] a color to be used for the borders the bars.
\item[\code{fit.norm}] a logical variable indicating whether to fit a normal density
curve \code{(TRUE)} or not \code{(FALSE)}.
\item[\code{lcol}] color of the normal density curve
\item[\code{stat}] the statistic to add on the graph. One of (\code{c("all","mean","median")}). Default is \code{NULL}.
\item[\code{stat.lab}] a character vector with the labels for the estimated mean and/or median. Default is \code{c("Mean","Median")}.
\item[\code{rug}] a logical variable indicating whether to superpose a \code{\LinkA{rug}{rug}}
\code{(TRUE)} or not \code{(FALSE)}.
\item[\code{main}] the main title of the graph
\item[\code{...}] additional arguments to be passed to plot (see \code{\LinkA{par}{par}})

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The default for \code{breaks} is \code{"Sturges"}: see
\code{\LinkA{nclass.Sturges}{nclass.Sturges}}.  Other names for which algorithms
are supplied are \code{"Scott"} and \code{"FD"} /
\code{"Freedman-Diaconis"} (with corresponding functions
\code{\LinkA{nclass.scott}{nclass.scott}} and \code{\LinkA{nclass.FD}{nclass.FD}}).
Alternatively, a function can be supplied which
will compute the intended number of breaks as a function of \code{x}.
\end{Details}
%
\begin{SeeAlso}\relax
\code{\LinkA{hist}{hist}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x=rnorm(50)
histplot(x)

norm.x=norm.test(x)
histplot(norm.x)  
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{inv.pred}{Inverse Predictions with SE}{inv.pred}
\keyword{\textbackslash{}textasciitilde{}kwd1}{inv.pred}
\keyword{\textbackslash{}textasciitilde{}kwd2}{inv.pred}
%
\begin{Usage}
\begin{verbatim}
inv.pred( object, cf=1:2, y )
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object of class \code{c('lm','glm')} resulting from a
calls to \code{c(\LinkA{lm}{lm},\LinkA{glm}{glm})}

\item[\code{cf}] the linear coefficients (\code{'intercept','slope')} to be used. 

\item[\code{y}] the \code{y} value for which \code{x} will be estimated with it's standard error.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
More to come. 
\end{Details}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
\newpage
\inputencoding{utf8}
\HeaderA{is.even}{is even}{is.even}
%
\begin{Description}\relax
Identifies if a value is even or not
\end{Description}
%
\begin{Usage}
\begin{verbatim}
is.even(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] numeric vector
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Will returns TRUE if \code{\LinkA{roundup}{roundup}}(x) is an even number.
\end{Details}
%
\begin{Value}
logical
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{is.odd}{is.odd}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
is.even(5)
is.even(6)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{is.odd}{is odd}{is.odd}
%
\begin{Description}\relax
Identifies if a value is odd or not
\end{Description}
%
\begin{Usage}
\begin{verbatim}
is.odd(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] numeric vector
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Will returns TRUE if \code{\LinkA{roundup}{roundup}}(x) is an odd number.
\end{Details}
%
\begin{Value}
logical
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{is.even}{is.even}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
is.odd(5)
is.odd(6)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{last}{last}{last}
%
\begin{Usage}
\begin{verbatim}
last(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{lev}{Levene type tests}{lev}
%
\begin{Description}\relax
Tests heteroscedasticity after an Anova
\end{Description}
%
\begin{Usage}
\begin{verbatim}
lev(y, ...)
## S3 method for class 'formula'
lev(y, data=NULL,  ...)
## S3 method for class 'lm'
lev(y, ...)
## Default S3 method:
lev(y, group, data=NULL , trim.alpha = 0.1, type="abs",...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{y}] response variable for the \code{default} method, \code{lm}
class object for the \code{lm} method or \code{formula}
class object for the \code{formula} methode. If \code{y}
is a linear-model object or a formula, the variables on the right-hand-side
of the model must all be factors and must be completely crossed. See details.
\item[\code{group}] for the default method, factor (concatenated factor when multiple factors). See details.
\item[\code{data}] \code{\LinkA{data.frame}{data.frame}} where the dependant variable and the factor(s) are
\item[\code{trim.alpha}] Alpha level (percentiles) trimming the data on which the mean will be evaluated
\item[\code{type}] Type of transformation made on the residuals. Either "abs" for absolute values or "sq" for sqared values
\item[\code{...}] arguments to be passed down, e.g., \code{data} for the
\code{formula} method or other options such as \code{type} and \code{trim.alpha}.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
When using the \code{lm} method, \code{data} doesn't need to be defined. When using the
\code{formula} or \code{default} methods, \code{data} can be defined if the data used
is in a \code{\LinkA{data.frame}{data.frame}}.

When group is manually defined in the default method, use \code{paste(x,y,z)} or\bsl{}*
\code{interaction(x,y,z)}form where\code{"x"}, \code{"y"} and \code{"z"}
are the factors. There is no restrictions on the number of factors.

O'Brien's (1981) performs test for equality of variances within each group:
based on transforming each observation in relation to its group variance
and its deviation from its group mean; and performing an ANOVA on these
transformed scores (for which the group mean is equal to the variance of the
original observations). The procedure is recognised to be robust against
violations of normality (unlike F-max).


\end{Details}
%
\begin{Value}

\begin{ldescription}
\item[\code{Model}] The model
\item[\code{Levene}] Results for Levene's test
\item[\code{LeveneTrimMean}] Results for Levene's test on the trimmed mean
\item[\code{Brown.Forsythe}] Results for Brown-Forsythe's test
\item[\code{OBrien}] Results for O'Brien's test

\end{ldescription}
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{leveneTest}{leveneTest}} from \code{\{car\}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
z=data.frame( yy=c(rep("c",50),rep("d",50)),
              x=c(rnorm(50),rnorm(50,10)),
              s=rep(c(rep("a",25),rep("b",25)),2),
              qq=rep(c(rep("w",10),rep("t",10)),5))

mod=lm(x~yy*qq*s, data=z)
formula= x~yy*qq*s

lev(y=x, group= paste(yy,qq,s), data=z, type="abs")
lev(y=x, group= paste(yy,qq,s), data=z, type="sq")

lev(y=x, group= interaction(yy,qq,s), data=z)

lev(y=formula, data=z)
lev(mod)

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{lib.code}{Retreives the code for \code{lib()}.}{lib.code}
%
\begin{Description}\relax
Will print in the R windows the code for \code{lib()} \bold{(READ DETAILS)}. 
\end{Description}
%
\begin{Usage}
\begin{verbatim}
lib.code()
lib(pack, install=TRUE, load=TRUE, quietly=TRUE, 
    warn.conflicts=FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pack}] Character vector specifying which package(s) to load/install.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax

\bold{USE \code{lib.code()} TO GET THE CODE FOR THE FUNCTION \code{lib()}.}


\code{lib.code()} prints in R the code for \code{lib()}. Copy and paste the code for \code{lib()}  
in the file \code{"C:/Program Files/R/R-2.12.1/etc/Rprofile.site"} (Windows) or \code{"\textasciitilde{}/.Rprofile"} (Mac).


\code{lib()} will load packages named in a charcater vector. If install is \code{TRUE}, 
packages not yet installed will be installed.

\end{Details}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}

lib.code()

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{lsmean}{Least Squares Means}{lsmean}
\methaliasA{lsmean.default}{lsmean}{lsmean.default}
\methaliasA{lsmean.listof}{lsmean}{lsmean.listof}
\methaliasA{lsmean.lm}{lsmean}{lsmean.lm}
\methaliasA{lsmean.lme}{lsmean}{lsmean.lme}
\methaliasA{lsmean.lmer}{lsmean}{lsmean.lmer}
\keyword{design}{lsmean}
%
\begin{Description}\relax
THIS FUNCTION IS FROM PACKAGE \code{pda} THAT IS STILL UNDER CONSTRUCTION ON
R-Forge. IT HAS BEEN INCLUDED IN \code{bmisc} FOR PRACTICAL REASONS.

\bold{Caution:} This routine is not fully tested for models with nested
factors or mixed models. Please check results against another
package (e.g. SAS proc mixed). It appears to correctly handle \code{lme}
objects, but does
not work well for \code{aov} objects that include \code{Error()}
type nesting in the formula. Further, it does not properly handle
polynomial terms--only the linear term is included. For now, create
dummies like x2 = x*x manually and include x2 in your model. 
\end{Description}
%
\begin{Usage}
\begin{verbatim}
lsmean(object, ...)
## Default S3 method:
lsmean(object, ..., factors, effects = FALSE, se.fit = TRUE,
   adjust.covar = TRUE)
## S3 method for class 'lm'
lsmean(object, data, factors, expr, contrast, effects = FALSE,
   se.fit = TRUE, adjust.covar = TRUE, pdiff = FALSE, 
   reorder = FALSE, lsd, level = .05, rdf, coef, cov, ...)
## S3 method for class 'lme'
lsmean(object, data, factors, ..., rdf, coef, cov)
## S3 method for class 'lmer'
lsmean(object, data, factors, expr, ..., rdf, coef, cov)
## S3 method for class 'listof'
lsmean(object, data, factors, stratum, expr, contrast, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] response vector (default) or model object (lm).
\item[\code{...}] factors and covariates (must be same length as y).
\item[\code{data}] data frame in which to interpret variables(found from
object if missing).
\item[\code{factors}] character vector containing names of x.factor and
trace.factoras first two entries.  Must be in \code{names(data)} and
\code{labels(object)}.Default is all factor names.
\item[\code{effects}] drop intercept if \code{TRUE} (only works properly with
sum-to-zero contrasts).
\item[\code{se.fit}] compute pointwise standard errors if T.
\item[\code{adjust.covar}] adjust means to average covariate values if
T; otherwise use covariate mean for each combination of
factors.
\item[\code{pdiff}] Include letters to signify significant differences.
\item[\code{reorder}] Reorder means from largest to smallest.
\item[\code{lsd}] Include average LSD if \code{TRUE} (also need \code{pdiff=TRUE}).
\item[\code{level}] Significance level for \code{pdiff} calculations.
\item[\code{rdf}] Residual degrees of freedom.
\item[\code{coef}] Coefficients for fixed effects in object.
\item[\code{cov}] Covariance matrix for fixed effects.
\item[\code{expr}] Call expression (formula)
\item[\code{contrast}] Type of contrasts (default is attribute
\code{contrasts} of \code{object})
\item[\code{stratum}] Name of stratum for lsmean calculation as character string.
\end{ldescription}
\end{Arguments}
%
\begin{Value}
Data frame containing unique factor levels of factors, predicted
response (pred) and standard errors (se). WARNING: lsmean may not
function properly if there are empty cells. Standard errors for mixed
models using methods \code{lmer} and \code{listof} are not fully
debugged.
\end{Value}
%
\begin{Author}\relax
Brian S. Yandell
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{predict}{predict}}.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
## Not run: 
lsmean(y,x1,x2)
# the following does the same thing
fit <- lm(y~x1+x2)
data <- data.frame(y,x1,x2)
lsmean(fit,data,factors=c("x1","x2")

## End(Not run)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{make.z}{make z}{make.z}
%
\begin{Usage}
\begin{verbatim}
make.z(x, index = NULL)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{index}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{mc.long}{Pairwise t tests in long format}{mc.long}
%
\begin{Description}\relax
Calculate pairwise T tests between group levels with corrections for multiple testing presented in long format
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mc.long(y, ...)
## S3 method for class 'formula'
mc.long( y, data=NULL, ...)
## S3 method for class 'lm'
mc.long( y, ...)
## Default S3 method:
mc.long(y, group,data=NULL, p.adjust.method="holm",
        column=NULL, digits=NULL, silent=FALSE, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{y}] response variable for the default method, or \code{lm} or
\code{\LinkA{formula}{formula}} object. If \code{y} is a linear-model object or a formula,
the variables on the right-hand-side of the model must all be factors and
must be completely crossed.
\item[\code{group}] for the default method, factor (concatenated factor when multiple factors). See details.
\item[\code{data}] \code{\LinkA{data.frame}{data.frame}} where the dependant variable and the factor(s) are
\item[\code{p.adjust.method}] method for adjusting p values. Default is Holm's method. (see \code{\LinkA{P.adjust}{P.adjust}}) 
\item[\code{column}] new names for the factor(s); this is optional 
\item[\code{digits}] controls the number of digits for the presented results presented
\item[\code{silent }] a logical variable indicating whether to indicate the general \code{warning} \code{(FALSE)} or not \code{(TRUE)}.
\item[\code{...}] additional arguments to pass to \code{\LinkA{P.adjust}{P.adjust}}, \code{\LinkA{pairwise.t.test}{pairwise.t.test}} and/or \code{\LinkA{t.test}{t.test}}. 
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
When making multiple t tests for all combinations, the \code{n} option of
\code{\LinkA{P.adjust}{P.adjust}} can be used to identify the number of comparisons that are actually used.
This is only to simplify the uses p values corrections on the full output
matrix when only some of the comparisons are meaningfull or chosen for hypothesis testing.


When \code{group} is manually defined, use \code{\LinkA{paste}{paste}(x,y,z)} or
\code{\LinkA{interaction}{interaction}(x,y,z)}form; \code{"x"}, \code{"y"} and \code{"z"} are the factors. There is no restrictions on the number of factors.


\end{Details}
%
\begin{Value}
Object of class \code{"data.frame"} containing the results.

\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{P.adjust}{P.adjust}}, \code{\LinkA{pairwise.t.test}{pairwise.t.test}}, \code{\LinkA{pair.diff}{pair.diff}}, \code{\LinkA{DTK.test}{DTK.test}}, \code{\LinkA{TukeyHSD}{TukeyHSD}} and \code{\LinkA{glht}{glht}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

z=data.frame( yy=c(rep("c",50),rep("d",50)),
              x=c(rnorm(50),rnorm(50,10)),
              s=rep(c(rep("a",25),rep("b",25)),2),
              qq=rep(c(rep("w",10),rep("t",10)),5))

mod=lm(x~yy*qq*s, data=z)
formula= x~yy*qq*s

mc.long(y=x, group= paste(yy,qq,s), data=z)
mc.long(y=x, group= paste(yy,qq,s), data=z, p.adjust.method="sidak")
mc.long(y=x, group= paste(yy,qq,s), data=z, p.adjust.method="sidak", n=15)
mc.long(y=x, group= interaction(yy,qq,s), data=z)

mc.long(y=formula, data=z)

mc.long(mod)

res <- mc.long(mod)   #### results are put in "res" object.

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{mse}{Mean square error}{mse}
%
\begin{Description}\relax
Estimates the mean square error (mse)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
mse(model)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{model}] an object containing the results of a model. 


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The mean square error is also known as the unexplained variance or the variance of the residuals.
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
z=data.frame( yy=c(rep("c",50),rep("d",50)),
              x=c(rnorm(50),rnorm(50,10)),
              s=rep(c(rep("a",25),rep("b",25)),2),
              qq=rep(c(rep("w",10),rep("t",10)),5))

mod=lm(x~yy*qq*s, data=z)

mse(mod)

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{n}{Sample size (n)}{n}
%
\begin{Description}\relax
Gives n without NA's
\end{Description}
%
\begin{Usage}
\begin{verbatim}
n(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 
Vector (numeric or character)

\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
x= rep(c(rnorm(30,20,5),NA),3)
n(x)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{norm.test}{Normality tests}{norm.test}
%
\begin{Description}\relax
Lilliefors (Kolmogorov-Smirnov), Shapiro-Francia, Shapiro-Wilk, 
D'Agostino Skewness, Anscombe-Glynn Kurtosis and D'Agostino-Pearson normality tests.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## Default S3 method:
 norm.test(norm.test(x, title=NULL, sk=c("G1","b1","mc"), type))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] one of:
\begin{itemize}

\item a numeric vector
\item an object of class \code{c('lm','aov','glm','gam')} resulting from a
calls to \code{c(\LinkA{lm}{lm},\LinkA{aov}{aov},\LinkA{glm}{glm},\LinkA{gam}{gam})}

\end{itemize}


\item[\code{title }] the title at the top of the results. Default is "Normality Tests".
\item[\code{sk }] type of skewness used in D'Agostino skewness test. Can be \code{"G1"},\code{"b1"} or \code{"mc"}. Read details.
\item[\code{type }] type of residuals which should be used. See details.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
This function can be used on objects belonging to \code{c('lm', 'aov', 'glm', 'gam')} classes. 
For example, \code{class(}aov.model\code{)} gives \code{"aov" "lm"} and \code{class(}glm.model\code{)} 
gives \code{"glm" "lm"}. The \code{type} of residuals can be defined. It generally includes 
\code{c("working", "response", "deviance", "pearson", "partial")}.

D'Agostino-Pearson's test is more appropriate for analysing a vector with
duplicate values in it. The more duplicate values in a vector, the more
Shapiro-Wilk will be far from correctly testing the \eqn{H0}{} hypothesis.

Given samples from a population, the equation for the sample skewness \eqn{g1}{}
is a biased estimator of the population skewness. The use of \eqn{G1}{} or \eqn{b1}{} is advisable.
For large samples, the various skewness estimates yield similar results. For small
normal distributed samples, \eqn{b1}{} is less biased than \eqn{G1}{}.
However, for small non-normal distributed samples, \eqn{G1}{} is less biased than \eqn{b1}{}.
These two skewness estimate can be sensitive to outliers in the data (contaminated data).
Therefore, the medcouple \code{\LinkA{mc}{mc}} is also an option in \code{type}. It has a good
performance on uncontaminated data and is robust on contaminated data.
For more information on medcouple, please read references and/or type \code{\LinkA{mc}{mc}} (\code{robustbase::mc}).

Here, d'Agostino skewness test is based on \code{mc} with default settings:

\begin{description}

\item[\eqn{g1=}{}] 
\eqn{m3 / m2^(3/2)}{}.

where \eqn{m3}{} is the sample third central moment, and \eqn{m2}{} is the sample variance.

This is the typical definition used in many older textbooks.

\item[\eqn{G1=}{}] 
\eqn{g1 * [k3/(k2^(3/2))] = g1 * [sqrt{n(n-1)} / (n-2)]}{}.

where \eqn{k3}{} is the unique symmetric unbiased estimator of the third
cumulant and \eqn{k2}{} is the symmetric unbiased estimator of the second cumulant.

Used in SAS and SPSS.

\item[\eqn{b1=}{}] 
\eqn{m3 / s^3 = g1 ((n-1)/n)^(3/2)}{}.

Used in MINITAB and BMDP.


\end{description}



More will be added to this section especially for Anscombe-Glynn Kurtosis test.
\end{Details}
%
\begin{Value}
An S4 object of class 'norm' containig the following components:

\begin{ldescription}
\item[\code{statistics}] the statistics for each analysis
\item[\code{p.value}] estimated p-values based on the statistics
\item[\code{data}] original data (\code{data.frame})
\item[\code{data.name }] names of the object called
\item[\code{title}] title for the result
\end{ldescription}
\end{Value}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{References}\relax
D. N. Joanes and C. A. Gill (1998),
Comparing measures of sample skewness and kurtosis.
\emph{The Statistician}, \bold{47}, 183--189.

G. Brys, M. Hubert and A. Struyf (2003),
A Comparison of Some NewMeasures of Skewness.
in \emph{Developments in Robust Statistics} \bold{ICORS 2001},
eds. R. Dutter, P. Filzmoser, U. Gather, and P.J. Rousseeuw, Heidelberg:
Springer-Verlag, 98--113

G. Brys, M. Hubert and A. Struyf (2004),
A Robust Measure of Skewness;
\emph{JCGS} \bold{13} (4), 996--1017.

\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{residuals}{residuals}}, \code{\LinkA{residuals.lm}{residuals.lm}}, \code{\LinkA{residuals.glm}{residuals.glm}}, and \code{\LinkA{residuals.gam}{residuals.gam}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
x <- rnorm(300, 50, 10)
y  <- 5*(x +10*(rnorm(300,1,2)))

norm.test(x)            ## mc skewness
norm.test(x, type="G1") ## G1 skewness
norm.test(x, type="b1") ## b1 skewness

mod <- lm(y~x)
norm.test(mod)

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{P.adjust}{Adjust P-values for Multiple Comparisons}{P.adjust}
\methaliasA{P.adjust.methods}{P.adjust}{P.adjust.methods}
%
\begin{Description}\relax
Given a set of p-values, returns p-values adjusted using
one of several methods.  This is a modified version of \code{\LinkA{p.ajust}{p.ajust}} from \code{\LinkA{stats}{stats}}.
It now includes \code{"sidak"} correction.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
P.adjust(p, method = P.adjust.methods, n = length(p))

P.adjust.methods
 c("holm", "hochberg", "hommel", "sidak", "bonferroni", "BH",
   "BY", "fdr", "none")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{p}] vector of p-values (possibly with \code{\LinkA{NA}{NA}}s).
\item[\code{method}] correction method
\item[\code{n}] number of pvalues considered for correction;
only set this (to non-default) when you know what you are doing! See details
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The adjustment methods include the Bonferroni correction
(\code{"bonferroni"}) in which the p-values are multiplied by the
number of comparisons.  Less conservative corrections are also
included by Holm (1979) (\code{"holm"}), Hochberg (1988)
(\code{"hochberg"}), Hommel (1988) (\code{"hommel"}), Benjamini \&
Hochberg (1995) (\code{"BH"}), and Benjamini \& Yekutieli (2001)
(\code{"BY"}), respectively.
A pass-through option (\code{"none"}) is also included.
The \code{P.adjust.methods} vector containes the set of correction methods
for the benefit of methods that need to have the method as an option
and pass it on to \code{P.adjust}.

The first five methods are designed to give strong control of the
family wise error rate.  There seems no reason to use the unmodified
Bonferroni correction because it is dominated by Holm's method, which
is also valid under arbitrary assumptions.

Hochberg's and Hommel's methods are valid when the hypothesis tests
are independent or when they are non-negatively associated (Sarkar,
1998; Sarkar and Chang, 1997).  Hommel's method is more powerful than
Hochberg's, but the difference is usually small and the Hochberg
p-values are faster to compute.

The \code{"BH"} and \code{"BY"} method of Benjamini, Hochberg, and
Yekutieli control the false discovery rate, the expected proportion of
false discoveries amongst the rejected hypotheses.  The false
discovery rate is a less stringent condition than the family wise
error rate, so these methods are more powerful than the others.

When making multiple comparisons, \code{n} can be used to identify the number
of comparisons that are actually used.
Correction is then done on the full output matrix when only some of the comparisons
are meaningfull or chosen for hypothesis testing. This can be done with the \code{"bonferroni"}
and \code{"sidak"} correction.
If other methods are used, exclude the unwanted \code{p.values} before applying correction.
Unless you know what you are doing, \bold{DO NOT} modify \code{n} if all comparisons are used. Most of the time \code{n}
should be equal to \code{length(p)}.

Note that you can set \code{n} larger than \code{length(p)} which
means the unobserved p-values are assumed to be greater than all the
observed p for \code{"bonferroni"} and \code{"holm"} methods and equal to 1 for
the other methods.
\end{Details}
%
\begin{Value}
A vector of corrected p-values (same length as \code{p}).
\end{Value}
%
\begin{References}\relax
Benjamini, Y., and Hochberg, Y. (1995).
Controlling the false discovery rate: a practical and powerful
approach to multiple testing.
\emph{Journal of the Royal Statistical Society Series} B, \bold{57},
289--300.

Benjamini, Y., and Yekutieli, D. (2001).
The control of the false discovery rate in multiple testing under
dependency.
\emph{Annals of Statistics} \bold{29}, 1165--1188.

Holm, S. (1979).
A simple sequentially rejective multiple test procedure.
\emph{Scandinavian Journal of Statistics}, \bold{6}, 65--70.

Hommel, G. (1988).
A stagewise rejective multiple test procedure based on a modified
Bonferroni test.
\emph{Biometrika}, \bold{75}, 383--386.

Hochberg, Y. (1988).
A sharper Bonferroni procedure for multiple tests of significance.
\emph{Biometrika}, \bold{75}, 800--803.

Shaffer, J. P. (1995).
Multiple hypothesis testing.
\emph{Annual Review of Psychology}, \bold{46}, 561--576.
(An excellent review of the area.)

Sarkar, S. (1998).
Some probability inequalities for ordered MTP2 random variables: a
proof of Simes conjecture.
\emph{Annals of Statistics}, \bold{26}, 494--504.

Sarkar, S., and Chang, C. K. (1997).
Simes' method for multiple hypothesis testing with positively
dependent test statistics.
\emph{Journal of the American Statistical Association}, \bold{92},
1601--1608.

Wright, S. P. (1992).
Adjusted P-values for simultaneous inference.
\emph{Biometrics}, \bold{48}, 1005--1013.
(Explains the adjusted P-value approach.)
\end{References}
%
\begin{SeeAlso}\relax
\code{\LinkA{pairwise.t.test}{pairwise.t.test}}, \code{\LinkA{mc.long}{mc.long}}, \code{\LinkA{DTK.test}{DTK.test}}, \code{\LinkA{TukeyHSD}{TukeyHSD}} and \code{\LinkA{glht}{glht}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
require(graphics)

set.seed(123)
x <- rnorm(50, mean=c(rep(0,25),rep(3,25)))
p <- 2*pnorm( sort(-abs(x)))

round(p, 3)
round(P.adjust(p), 3)
round(P.adjust(p,"BH"), 3)

## or all of them at once (dropping the "fdr" alias):
P.adjust.M <- P.adjust.methods[P.adjust.methods != "fdr"]
p.adj <- sapply(P.adjust.M, function(meth) P.adjust(p, meth))
round(p.adj, 3)
## or a bit nicer:
noquote(apply(p.adj, 2, format.pval, digits = 3))

## and a graphic:
matplot(p, p.adj, ylab="P.adjust(p, meth)", type = "l", asp=1, lty=1:6,
        main = "P-value adjustments")
legend(.7,.6, P.adjust.M, col=1:6, lty=1:6)

## Can work with NA's:
pN <- p; iN <- c(46,47); pN[iN] <- NA
pN.a <- sapply(P.adjust.M, function(meth) P.adjust(pN, meth))
## The smallest 20 P-values all affected by the NA's :
round((pN.a / p.adj)[1:20, ] , 4)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{pack.list}{List of installed packages}{pack.list}
%
\begin{Description}\relax
Create a text file containing the list of the packages currently installed in R.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
pack.list(n.names=7)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{n.names}] 
Number of package names to put per line of the output text file.

\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
pack.list()
pack.list(5)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{pair.diff}{Mean differences matrix and their associated standard Errors}{pair.diff}
%
\begin{Description}\relax
Creates two lower triangle matrix: The mean differences and their standard error.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
pair.diff(y, ...)
## S3 method for class 'formula'
pair.diff(y, data=NULL ...)
## S3 method for class 'lm'
pair.diff( y, ...)
## Default S3 method:
pair.diff( y, group, data=NULL, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{y}] response variable for the default method, or \code{lm} or
\code{\LinkA{formula}{formula}} object. If \code{y} is a linear-model object or a formula,
the variables on the right-hand-side of the model must all be factors and
must be completely crossed.
\item[\code{group}] for the default method, factor (concatenated factor when multiple factors). See details.
\item[\code{data}] \code{data.frame} where the dependant variable and the factor(s) are.
\item[\code{...}]  additional arguments to pass to \code{\LinkA{mean}{mean}} and/or \code{\LinkA{sd}{sd}}. 
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
When group is manually defined, use \code{paste(x,y,z)} or \code{interaction(x,y,z)}form where\code{"x"}, \code{"y"} and \code{"z"} are the factors. There is no restrictions on the number of factors.

This function can be usefull with \code{\LinkA{pairwise.t.test}{pairwise.t.test}} since the matrix created are of the same format.
\end{Details}
%
\begin{Value}
Object of class \code{"list"} containing two matrices:

\begin{ldescription}
\item[\code{diff.m  }] Mean differences half matrix 
\item[\code{diff.se }] Standard error associated with the mean differences half matrix

\end{ldescription}
\end{Value}
%
\begin{SeeAlso}\relax
Is included in \code{\LinkA{mc.long}{mc.long}} for the long format of the results.
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

z=data.frame( yy=c(rep("c",50),rep("d",50)),
              x=c(rnorm(50),rnorm(50,10)),
              s=rep(c(rep("a",25),rep("b",25)),2),
              qq=rep(c(rep("w",10),rep("t",10)),5))

mod=lm(x~yy*qq*s, data=z)
y= x~yy*qq*s

pair.diff(y=x, group= paste(yy,qq,s), data=z)
pair.diff(y=x, group= interaction(yy,qq,s), data=z)
pair.diff(y=y, data=z)
pair.diff(mod)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{performance}{performance}{performance}
%
\begin{Usage}
\begin{verbatim}
performance(expr, samples = 1, gcFirst = TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{expr}] 


\item[\code{samples}] 


\item[\code{gcFirst}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{plot.logit}{Standard plot for maturity ogive}{plot.logit}
\keyword{\textbackslash{}textasciitilde{}kwd1}{plot.logit}
\keyword{\textbackslash{}textasciitilde{}kwd2}{plot.logit}
%
\begin{Usage}
\begin{verbatim}
plot.logit(object, se.pred=TRUE, leg=TRUE, ref=TRUE, range.x=c("data","full"), 
         warn.val=TRUE, ylab="Probabiliti",xlab="Longueur ` la fourche (mm)")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object of class \code{'glm'} resulting from a call to \code{\LinkA{glm}{glm}}.

\item[\code{se.pred}] logical; if TRUE, SE is plotted.

\item[\code{leg}] logical; if TRUE, a legend containing logistic equation and estimated values for the variables is plotted.

\item[\code{ref}] logical; if TRUE, reference lines for \code{L90, L50 and L10} are plotted.

\item[\code{range.x}] the range used to define \code{xlim} in the plot. Read 'details'.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
More to come.
\end{Details}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
\newpage
\inputencoding{utf8}
\HeaderA{plot.ypr}{Standard Yield per Recruit plot.}{plot.ypr}
%
\begin{Description}\relax
Yield per Recruit and Spawning Stock Biomass per Recruit are plotted with standard reference points. 
\end{Description}
%
\begin{Usage}
\begin{verbatim}
 ## S3 method for class 'ypr'
plot.ypr(object, main, ylab.ypr, ylab.ssb, xlab, col.ypr, col.ssb, ref, legend)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object of class \code{"ypr"} resulting from a
call to \code{\LinkA{ypr.l}{ypr.l}}

\item[\code{main}] main title for the graph

\item[\code{ylab.ypr}] a label for the YPR \code{y} axis

\item[\code{ylab.ssb}] a label for the SSB/R \code{y} axis

\item[\code{xlab}] a label for the YPR \code{x} axis.

\item[\code{col.ypr}] the color of the the color of the YPR line.

\item[\code{col.ssb}] the color of the the color of the SSB/R line.

\item[\code{ref}] logical; if \code{TRUE}, standard reference points are added to the plot.

\item[\code{legend}] logical; if \code{TRUE}, a legend is added in the \code{'topright'} corner of the plot.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
More to come.
\end{Details}
%
\begin{SeeAlso}\relax
\code{\LinkA{ypr.l}{ypr.l}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
ypr.mod = ypr.l(fsel.type=list("ramp",650,900), vonB=c(1564.512,0.1205765), 
                l.start=72.53,last.age=25,LW=c(exp( -18.47894),3.043), F.max=2,
                F.incr.YPR=0.01, M=0.2, mat=list('full',900), f.MSP=0.4, riv.calc=F)  

plot(ypr.mod)

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{QQplot}{QQplot}{QQplot}
%
\begin{Usage}
\begin{verbatim}
QQplot(dat, quant=TRUE,cex.q=2,norm=T, ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{dat}] one of:
\begin{itemize}

\item a numeric vector
\item an object of class \code{c('norm','lm','aov','glm','gam')} resulting from a
calls to \code{c(\LinkA{norm.test}{norm.test},\LinkA{lm}{lm},\LinkA{aov}{aov},\LinkA{glm}{glm},\LinkA{gam}{gam})}

\end{itemize}


\item[\code{quant}] logical; T for adding quantiles 75, 50 (median) and 25.
\item[\code{cex.q}] numeric vector giving the amount by which plotting symbols should be magnified relative to the default
\item[\code{norm}] logical; T adds a line to a normal quantile-quantile plot.
\item[\code{...}] additional arguments to be passed (see \code{\LinkA{par}{par}}, \code{\LinkA{qqnorm}{qqnorm}})
\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
x=rnorm(50)
QQplot(x)

norm.x=norm.test(x)
QQplot(norm.x)  
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{r.colors}{Pie charts of all R character colors}{r.colors}
%
\begin{Description}\relax
Creates a pdf file with pie charts of all the 657 basic character colors of R
\end{Description}
%
\begin{Usage}
\begin{verbatim}
r.colors(file)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{file}] 
the directory in which the pdf file will be created


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Define the directory in which the file should saved by writing \code{file="C:/temp"} for example.
If file is not defined, it will be saved in \code{"C:/"} on windows and in \code{"home"} on Mac.
\end{Details}
%
\begin{Value}
None
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
r.colors()
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{reject.z}{reject z}{reject.z}
%
\begin{Usage}
\begin{verbatim}
reject.z(x, index = NULL, threshold = 2)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{index}] 


\item[\code{threshold}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{replace.z}{replace z}{replace.z}
%
\begin{Usage}
\begin{verbatim}
replace.z(x, index = NULL, threshold = 2)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{index}] 


\item[\code{threshold}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{resid.ortho}{Orthogonal residuals}{resid.ortho}
\keyword{\textbackslash{}textasciitilde{}kwd1}{resid.ortho}
\keyword{\textbackslash{}textasciitilde{}kwd2}{resid.ortho}
%
\begin{Usage}
\begin{verbatim}
xxx( data ,  ,  ,  )
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] 


\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
\newpage
\inputencoding{utf8}
\HeaderA{rivard}{Rivard Weights Calculation}{rivard}
%
\begin{Description}\relax
This function applies Rivard equations to mid-year weight at age data to adjust values to Jan-1 basis. 
\end{Description}
%
\begin{Usage}
\begin{verbatim}
rivard(pds, pred=FALSE, K=2, plus.gr=FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] 


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
More to come.  Will be adding interpolation for spawning season.
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}

x=rnorm(30,800,10)
rivard(data.frame("2000"=x,"2001"=x*1.2, "2002"=x*0.8,"2003"=x*0.5))

\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{rm.levels}{rm factor levels}{rm.levels}
%
\begin{Usage}
\begin{verbatim}
rm.levels(factor)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{factor}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{rollmin}{rollmin}{rollmin}
%
\begin{Usage}
\begin{verbatim}
rollmin(x, k, na.pad = FALSE, align = c("center", "left", "right"),
        ...)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{k}] 


\item[\code{na.pad}] 


\item[\code{align}] 


\item[\code{...}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{roundup}{roundup}{roundup}
%
\begin{Description}\relax
The "conventional" rounding of 5 to the higher value
\end{Description}
%
\begin{Usage}
\begin{verbatim}
roundup(x, numdigits = 0)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] numeric vector.
\item[\code{digits}] integer indicating the number of decimal places to be used.
\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax

Rounds a 5 to the next value. Therefore roundup(2.5) is 3.
This can be usefull when the rounded values are to be presented in a document (eg. table, graph,...).

When rounded values are used in other calculations, \code{\LinkA{round}{round}} should be
used since it follows the IEC 60559 standard.
\end{Details}
%
\begin{Value}
numeric vector.
\end{Value}
%
\begin{SeeAlso}\relax
\code{\LinkA{round}{round}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}
round(2.5)
roundup(2.5)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{runmax}{runmax}{runmax}
%
\begin{Usage}
\begin{verbatim}
runmax(x, window)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{window}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{runmean}{runmean}{runmean}
%
\begin{Usage}
\begin{verbatim}
runmean(x, window)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{window}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{runmin}{runmin}{runmin}
%
\begin{Usage}
\begin{verbatim}
runmin(x, window)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\item[\code{window}] 


\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{s.an}{Simulations for YPR model}{s.an}
\keyword{\textbackslash{}textasciitilde{}kwd1}{s.an}
\keyword{\textbackslash{}textasciitilde{}kwd2}{s.an}
%
\begin{Description}\relax
Not ready yet. Use \code{\LinkA{for}{for}} loops for now.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
xxx( data ,  ,  ,  )
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{data}] 


\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
\newpage
\inputencoding{utf8}
\HeaderA{se}{Standard Error}{se}
%
\begin{Usage}
\begin{verbatim}
se(x, na.rm=T)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] an \R{} object (vector, matrix,...)

\item[\code{na.rm}] a logical value indicating whether NA values should be stripped before the computation proceeds

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The standard error of the mean is usually estimated by the sample standard deviation 
divided by the square root of the sample size.
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
x=rnorm(50)
se(x)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{show.North}{North arrow for a map}{show.North}
%
\begin{Description}\relax
Draws North arrow on a map
\end{Description}
%
\begin{Usage}
\begin{verbatim}
show.North(pos, arrow.col="black", arrow.fill="black", arrow.lwd=1,
           N.cex=1, N.family="HersheyGothicEnglish")
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pos}] Position of the arrow. Default is \code{'topright'}. See details.

\item[\code{arrow.col}] Arrow color.

\item[\code{arrow.fill}] Color inside the head of the arrow. \code{NA} for no color.

\item[\code{arrow.lwd}] Line width of the arrow.

\item[\code{N.cex}] Character size for 'N'.

\item[\code{N.family}] Font family of 'N'.


\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The position of the north arrow is defined by \code{pos} and can either be numeric or character.

If \code{pos} is numeric, it is a vector of the form \code{c(x,y)} where \code{x} and \code{y} are fractions of the plotting region.
If \code{x} and \code{y} are not in the range of \code{c(0,1)}, then the north arrow is drawn ouside the bounds of the plotting region 
and a warning message is given.

If \code{pos} is character, it is one of \code{c('topright','topleft','bottomright','bottomleft')}.

\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
plot(1)
show.North()
show.North(c(0.8,0.9))
show.North(c(1.01,0.9))  ### gives a warning
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{sort.vdf}{Sort Data Frames and Vectors}{sort.vdf}
%
\begin{Description}\relax
Single function enabling \code{data.frame} and \code{vector} sorting
\end{Description}
%
\begin{Usage}
\begin{verbatim}
sort.vdf(x, by, increasing=TRUE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] \code{data.frame} or \code{vector}
\item[\code{by}] A one-sided formula using + for ascending and - for descending. Sorting is left to right in the formula. This is for data.frame only.
\item[\code{increasing}] logical. Should the sort be increasing \code{(TRUE)} or decreasing \code{(FALSE)}? This is for sorting vectors only.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
See example.
\end{Details}
%
\begin{Author}\relax
Kevin Wright and modified by Benoit Bruneau
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
x=rnorm(10)
y=runif(30)
z=data.frame(x,y)

sort.vdf(x)                 ### Sort a vector in increasing order
sort.vdf(z)                 ### Gives an error message
sort.vdf(z,by= ~ +x)        ### Sort (z) by a column (+x)
sort.vdf(z,by= ~ +x +y)     ### Sort (z) by two column (+x and then +y)
sort.vdf(z,by= ~ +x -y)     ### Sort (z) by two column (+x and then -y)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{summary.ypr}{Summarizing the results of YPR models.}{summary.ypr}
\keyword{\textbackslash{}textasciitilde{}kwd1}{summary.ypr}
\keyword{\textbackslash{}textasciitilde{}kwd2}{summary.ypr}
%
\begin{Description}\relax
\code{summary} method for class \code{"ypr"}.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
## S3 method for class 'ypr'
summary(object)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{object}] an object of class \code{"ypr"} resulting from a
call to \code{\LinkA{ypr.l}{ypr.l}}.

\end{ldescription}
\end{Arguments}
%
\begin{Examples}
\begin{ExampleCode}
ypr.mod = ypr.l(fsel.type=list("ramp",650,900), vonB=c(1564.512,0.1205765), 
                l.start=72.53,last.age=25,LW=c(exp( -18.47894),3.043), F.max=2,
                F.incr.YPR=0.01, M=0.2, mat=list('full',900), f.MSP=0.4, riv.calc=F)  

summary(ypr.mod)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{ttest.perm}{Student's t-tests by Permutation}{ttest.perm}
\keyword{ttest}{ttest.perm}
%
\begin{Description}\relax
Performs two sample t-tests  or paired t-test by use of permutation
\end{Description}
%
\begin{Usage}
\begin{verbatim}
ttest.perm(vec1, vec2, nperm=999, alternative = "two.sided",
           var.equal = T, silent=FALSE, type="i", exact=FALSE)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{vec1, vec2 }] 
two numeric vectors used for Student's t-test analysis

\item[\code{nperm }] 
number of permutations (default = 999)

\item[\code{alternative }] 
one of the following: "two.sided", "less" or "greater".

\item[\code{var.equal }] 
a logical variable indicating whether to treat the two variances as being equal (\code{TRUE}) or not (\code{FALSE}).

\item[\code{silent }] 
a logical variable indicating whether calculation results are printed (\code{FALSE}) to the R console or not (\code{TRUE}).

\item[\code{type }] 
one of the following: "i" for independant samples or "p" for paired samples.

\item[\code{exact }] 
a logical variable indicating whether to perform the exact test (\code{TRUE}) or not (\code{FALSE}).

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
The permutational t-test does not require normality of the distributions of each variable.
It is also quite robust to heteroscedasticity.

Use \code{exact=TRUE} to perform two sample t-test on all the possible combination.
This option can only be used when the sum of the sample sizes \eqn{(n{_1}+n{_2})}{} is smaller than 20.
It is recommended to use this option when sample sizes are small.
It is not implemented yet in the paired t-test.

\code{nperm} can not be higher than the maximum number of combination possible (\eqn{n_{comb}}{}).

\begin{description}

\item[\eqn{n_{comb} =}{}] \eqn{N! / (n{_1}!n{_2}!)}{}


where \code{n\_comb} is the number of possible combinations, \eqn{N!}{}
is \code{\LinkA{factorial}{factorial}\eqn{(n{_1}+n{_2})}{}}, \eqn{n{_1}!}{} is
\code{\LinkA{factorial}{factorial}(\LinkA{n}{n}(vec1))} and \eqn{n{_2}!}{} is
\code{\LinkA{factorial}{factorial}(\LinkA{n}{n}(vec2))}.
\end{description}


There is more to come in this section. plot(x)

5 [ sup ] 7



\end{Details}
%
\begin{Value}
\begin{ldescription}
\item[\code{t.ref }] reference value of the t-statistic
\item[\code{p.param }] parametric p-value
\item[\code{p.perm }] permutational p-value
\item[\code{nperm }] number of permutations
\item[\code{perm.t }] list of the t statistics (only for independant sample ttest), starting with the reference value, followed by all values obtained under permutations.
\end{ldescription}
\end{Value}
%
\begin{Examples}
\begin{ExampleCode}
x <- rnorm(50,0,1)
y <- runif(50,0,1)*x
toto = ttest.perm(x, y)  ##independant samples ttest
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{unload}{Unload packages}{unload}
%
\begin{Description}\relax
Unloads one or multiple packages.
\end{Description}
%
\begin{Usage}
\begin{verbatim}
unload(pack)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{pack}] Character vector specifying which packages to unload.

\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
library(mgcv)
search()
unload(mgcv)
search()
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{week.1}{week.1}{week.1}
%
\begin{Description}\relax
 Week of the year starting on the first of January (01-53)
\end{Description}
%
\begin{Usage}
\begin{verbatim}
week.1(x)
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 


\end{ldescription}
\end{Arguments}
%
\begin{Author}\relax
Denis Chabot
\end{Author}
%
\begin{Examples}
\begin{ExampleCode}
# will soon be available
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{week.num}{week.num}{week.num}
%
\begin{Description}\relax
Week of the year as decimal number (00-53) using Sunday or Monday as 
the first day 1 of the week (and typically with the first Sunday of the year as day 1 of week 1).
\end{Description}
%
\begin{Usage}
\begin{verbatim}
week.num(x, day=c("sunday", "monday"))
\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{x}] 
A vector of dates.

\item[\code{day}] 
Either "sunday" or "monday". Default is "sunday".

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
Argument \code{day} indicates if the week starts on \code{"sunday"} or \code{"monday"}.
\end{Details}
%
\begin{Examples}
\begin{ExampleCode}
dated <-as.Date(c("2006-05-18","2006-05-07","2006-04-23",
                  "2006-04-24","2006-05-07","2007-05-17",
                  "2007-05-06","2007-04-22","2007-04-29"))
                  
week.num(dated, "monday")
week.num(dated)
\end{ExampleCode}
\end{Examples}
\newpage
\inputencoding{utf8}
\HeaderA{ypr.l}{Length Based Yield Per Recruit }{ypr.l}
%
\begin{Description}\relax
Length based Yield Per Recruit model is define by fishery selectivity and life history parameters related to length. 


\end{Description}
%
\begin{Usage}
\begin{verbatim}
 ypr.l(LW, vonB, l.start, last.age, age.step=1, Fsel.type, 
       F.max=2,F.incr.YPR=0.0001, M.l,  M=0.2, f.MSP=0.4, 
       F.f=0, M.f=0.5, riv.calc=FALSE)

\end{verbatim}
\end{Usage}
%
\begin{Arguments}
\begin{ldescription}
\item[\code{LW}] one of:
\begin{itemize}

\item a vector containing \code{c(\eqn{\alpha}{},\eqn{\beta}{})} from length-weight curve. See 'Details'. 
\item an object of class \code{'nls'} in which \eqn{\alpha}{} and \eqn{\beta}{} were estimated. See 'Details'.        

\end{itemize}


\item[\code{vonB}] one of:
\begin{itemize}

\item a vector containing \code{c(Linf,K)} from von Bertalanffy grotwh curve. See 'Details'. 
\item an object of class \code{'glm'} in which eqnLinf and eqnK were estimated. See 'Details'.        

\end{itemize}


\item[\code{l.start}] length at the starting age

\item[\code{last.age}] last age to be considered in the model

\item[\code{age.step}] steps used to generate ages. Default is \code{1}.

\item[\code{Fsel.type}] one of:
\begin{itemize}

\item a list containing the type of fishery selectivity and the values needed for the function related to the type. See 'Details'. 
\item an object of class \code{'glm'} in which \eqn{\alpha}{} and \eqn{\beta}{} were estimated by a logistic regression. See 'Details'.        

\end{itemize}


\item[\code{F.max}] maximum value of instantaneous rate of fishing mortality (\code{F}). Default is 2.

\item[\code{F.incr.YPR}] increment for generating the \code{F} values to be used for YPR calculation. Default is 0.0001.

\item[\code{M.l}] one of:
\begin{itemize}

\item a list containing the type of maturity at length definition and the values needed for the function related to the type. See 'Details'. 
\item an object of class \code{'glm'} in which \eqn{\alpha}{} and \eqn{\beta}{} were estimated by a logistic regression. See 'Details'.        

\end{itemize}


\item[\code{M}] instantaneous rate of natural mortality (\code{M}). Default is 0.2.

\item[\code{f.MSP}] reference point defined as the fraction of maximum spawning potential. Default is 0.4.

\item[\code{F.f}] fraction of instantaneous rate of fishing mortality (\code{F}) before spawning.

\item[\code{M.f}] fraction of instantaneous rate of natural mortality (\code{M}) before spawning.

\item[\code{riv.calc}] a logical value indicating whether to use Rivard weights calculation (\code{TRUE}) or not. Default is \code{FALSE}.

\end{ldescription}
\end{Arguments}
%
\begin{Details}\relax
\bold{Length-Weight relationship} can be provided either by indicating \code{c(\eqn{\alpha}{},\eqn{\beta}{})} values in a vector or by 
directly using an object of class \code{'nls'} or \code{'lm'}. If \eqn{\alpha}{} and \eqn{\beta}{} are estimated 
by \code{lm}, \code{log(x, base=exp(1))} transformation should be applied to the data prior to fitting the linear model. 
If an object resulting from \code{nls} is used, variables should be named \bold{alpha} and \bold{beta} 
using the following equation:

\Tabular{c}{
\eqn{W=\alpha L^\beta}{}
}
where \eqn{W}{} is weight, \eqn{L}{} is length, \eqn{\alpha}{} is the elevation of the curve, and \eqn{\beta}{} 
is the steepness of the curve. Both \eqn{\alpha}{} and \eqn{\beta}{} are coefficients estimated by the regression. 


\bold{Von Bartalanffy growth equation} parameters can be provided either by indicating \code{c(Linf,K)} values in a vector or by 
directly using an object of class \code{'nls'}. If an object resulting from \code{\LinkA{nls}{nls}} is used, variables 
should be named \bold{Linf} and \bold{K}. As for \eqn{t_0}{}, any name may be used since only \eqn{L_{\infty }}{} and \eqn{K}{} are 
used in this length-based YPR model. The equation used in the \code{\LinkA{nls}{nls}} for estimating \eqn{L_{\infty }}{} 
and \eqn{K}{} should be the following one:

\Tabular{c}{
\eqn{ L_t=L_{\infty }\bigg{(} 1-e^{-K (t-t_0)}\bigg{)} }{}
}
where \eqn{L_t}{} is length-at-age \eqn{t}{}, \eqn{L_{\infty }}{} is the asymptotic average maximum length, 
\eqn{K}{} is a growth rate coefficient determinant of how quick the maximum is attained, and \eqn{t_0}{} 
is the hypothetical age at length zero.

As stated above, since this length-based YPR model uses relative age, \eqn{t-t_0}{} becomes a relative age (\eqn{a}{}). 
The Von Bartalanffy growth equation used in this length-based YPR model is defined as:

\Tabular{c}{
\eqn{ L_a=L_{\infty }\bigg{(} 1-e^{-Ka}\bigg{)}+ L_s e^{-Ka} }{}
}
where \eqn{L_a}{} is length at a relative age \eqn{a}{} and \eqn{L_s}{} is length at relative age zero.


The \bold{fishery selectivity} and \bold{maturity at length} components of the model can be defined 
as one of \code{c("full", "ramp", "logistic")} equations. The proper way to specify which equation to use is by 
the construct of a \code{list} where the first element is the name of one of the three types of equation. 
The following elements of the \code{list} are specific to the type of equation:
\begin{itemize}

\item \bold{full:}  element \code{[[2]]} is the length at which full maturity is achieved.

\item \bold{ramp:}  element \code{[[2]]} is the maximum length at which maturity is null and 
element \code{[[3]]} is the minimum length at which maturity is fully achieved.

\item \bold{logistic}  elements \code{[[2]]} and \code{[[3]]} are respectively \eqn{\alpha}{} and \eqn{\beta}{} 
components of a logistic curve.

\end{itemize}

Alternatively, an object of class \code{'glm'} can directly be used for the \bold{fishery selectivity} and \bold{maturity at length} components. 
The Generalized Linear Model should have  the option \code{family} set to either \code{binomial} or \code{quasibinomial} keeping link function to the 
default (\eqn{i.e.}{} \code{"logit"}).
Estimated coefficients are use as follow: 

\Tabular{c}{
\eqn{y=\frac{1}{1+e^{-(\alpha+\beta x)}}}{} 
}


\bold{Reference points} used for result output are defined as:
\begin{itemize}

\item \bold{F.zero:}  F level when there is no fishing (F=0).
\item \bold{F.01}  F level where the slope of yield curve is 10\% of the slope at \code{F.zero}. 
\item \bold{F.xx}  F level where the MSP is at the level defined by \code{f.MSP} option. Default is 40\% (0.4).
\item \bold{F.max}  F level where yield is maximum.

\end{itemize}


More to come.
\end{Details}
%
\begin{Value}
\code{ypr.l} returns an object of \code{\LinkA{class}{class}(S4)} \code{"ypr"}. The functions \code{summary} and \code{plot} are used to respectively
obtain a summary and a standard plot of the results.  

An object of class \code{"ypr"} has the the following slots:


\begin{ldescription}
\item[\code{parms}] the list of parameters used in the model.
\item[\code{base}] a \code{\LinkA{data.frame}{data.frame}} containing the starting values:
\begin{itemize}

\item relative age classes
\item length at age
\item weight at age

\end{itemize}


\item[\code{refs}] a \code{\LinkA{data.frame}{data.frame}} containing values predicted by the model for the four reference points. See details. 
\item[\code{YPR}] a \code{\LinkA{data.frame}{data.frame}} containing the results for all partial Fs.


\end{ldescription}
Note that to have access to each slot of an \code{"ypr"} object, one must use \code{"@"} instead of \code{"\$"}.
\end{Value}
%
\begin{Author}\relax
Benoit Bruneau
\end{Author}
%
\begin{SeeAlso}\relax
\code{\LinkA{plot.logit}{plot.logit}}
\end{SeeAlso}
%
\begin{Examples}
\begin{ExampleCode}

ypr.l(fsel.type=list("ramp",650,900), vonB=c(1564.512,0.1205765), 
      l.start=72.53,last.age=25,LW=c(exp( -18.47894),3.043), F.max=2,
      F.incr.YPR=0.01, M=0.2, mat=list('full',900), f.MSP=0.4, riv.calc=F) 

\end{ExampleCode}
\end{Examples}
\printindex{}
\end{document}
